# Local-research-assistant-by-LLM
Offline research assistant using LLaMA 3, FAISS, and Retrieval-Augmented Generation (RAG) to answer questions from a local textbook dataset.
